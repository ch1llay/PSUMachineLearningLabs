{"nbformat":4,"nbformat_minor":0,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"nbTranslate":{"displayLangs":["*"],"hotkey":"alt-t","langInMainMenu":true,"sourceLang":"en","targetLang":"fr","useGoogleTranslate":true},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Лабораторная 23. Ансамбли. Стекинг.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"604HgvDEHbMj","executionInfo":{"status":"ok","timestamp":1613315831271,"user_tz":-180,"elapsed":5069,"user":{"displayName":"ИТ-класс в московской школе","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_ha7QOa0FMhe4Cp-P78YhxGwsJVkSvH-MURQ=s64","userId":"09176086438558815619"}},"outputId":"16bf47fc-5c1d-46f8-a40b-1ceee89a2298"},"source":["!git clone https://github.com/stuniy/SPO_PGU.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'ML_School'...\n","remote: Enumerating objects: 56, done.\u001b[K\n","remote: Counting objects: 100% (56/56), done.\u001b[K\n","remote: Compressing objects: 100% (55/55), done.\u001b[K\n","remote: Total 56 (delta 14), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (56/56), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GOWjrSeVHacq"},"source":["# Ансамбли. Стекинг\n","Еще один вариант ансамблей - стекинг - когда объединяются результаты разнородных моделей с помощью еще одной модели.\n","В `sklearn` реализованы \n","* [`StackingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier)  - классификатор\n","* [`StackingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor) - регрессор\n","\n","Аргументы для создания ансамблей: \n","* `estimators` - кортеж из названий и объектов моделей ансамбля\n","* `final_estimator` - модель для объединения результатов, по умолчанию `LogisticRegression` для классификатора и `RidgeCV` для регрессора.\n","* `cv` - число разбиений для кроссвалидации (или объекты) \n","stack_method - по какому именно результату объядинять модели: ‘auto’, ‘predict_proba’, ‘decision_function’, ‘predict’,\n","* `verbose` - число, определяющее как подробно выводить информацию об обучении, по умолчанию 0 - не выводить\n","* `passthrough` - использовать ли для обучения финальной модели сами данные или только результаты моделей ансамбля.\n","\n","Создаваемые модели имеют атрибуты \n","\n","* `estimators_` - список обученных моделей в ансамбле\n","* `final_estimator_` - обученная финальная модель\n","* `named_estimators_` - контейнер для доступа к параметрам моделей по их названию\n","* `classes_` - для классификатора метки классов\n","\n","Реализованные методы аналогичны: `fit()`, `pedict()`, ... \n","\n","Реализованы также  [`VotingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier) и [`VotingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html#sklearn.ensemble.VotingRegressor), отличающиеся тем, что в качестве финальной модели используется процедура голосования.\n","\n"]},{"cell_type":"markdown","source":["## Классификатор голосования\n","Идея `VotingClassifier` состоит в том, чтобы объединить концептуально разные классификаторы машинного обучения и использовать большинство голосов или средние предсказанные вероятности (мягкое голосование) для прогнозирования меток классов. Такой классификатор может быть полезен для набора одинаково хорошо работающих моделей, чтобы уравновесить их индивидуальные недостатки.\n","\n","## Ярлыки класса большинства (большинство / жесткое голосование)\n","При голосовании большинством прогнозируемая метка класса для конкретной выборки является меткой класса, которая представляет большинство (режим) меток класса, предсказываемых каждым отдельным классификатором.\n","\n","Например, если прогноз для данной выборки\n","\n","классификатор 1 -> класс 1\n","\n","классификатор 2 -> класс 1\n","\n","классификатор 3 -> класс 2\n","\n","\n","Классификатор `VotingClassifier (с voting='hard')` классифицирует образец как «класс 1» на основе метки класса большинства.\n","\n","В случае совпадения `VotingClassifier` класс будет выбран в соответствии с возрастающим порядком сортировки. Например, в следующем сценарии\n","\n","классификатор 1 -> класс 2\n","\n","классификатор 2 -> класс 1\n","\n","метка класса 1 будет присвоена образцу.\n","\n","В следующем примере показано, как соответствовать классификатору правил большинства:\n"],"metadata":{"id":"d9281S3egDty"}},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-10-11T11:17:47.374170Z","start_time":"2020-10-11T11:17:44.432001Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"gwzm_I-AHacs","executionInfo":{"status":"ok","timestamp":1660634399027,"user_tz":-180,"elapsed":1455,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"e042608e-f68c-4ba3-b442-67a672b6e1ab"},"source":["from sklearn import datasets\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import VotingClassifier\n","\n","iris = datasets.load_iris()\n","X, y = iris.data[:, 1:3], iris.target\n","\n","clf1 = LogisticRegression(random_state=1)\n","clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n","clf3 = GaussianNB()\n","\n","eclf = VotingClassifier(\n","     estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n","     voting='hard')\n","\n","for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'GaussianNB', 'Ensemble']):\n","     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n","     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.95 (+/- 0.04) [Logistic Regression]\n","Accuracy: 0.94 (+/- 0.04) [Random Forest]\n","Accuracy: 0.91 (+/- 0.04) [GaussianNB]\n","Accuracy: 0.95 (+/- 0.04) [Ensemble]\n"]}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-10-11T11:17:47.379170Z","start_time":"2020-10-11T11:17:47.375170Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"kGoA8a9eHact","executionInfo":{"status":"ok","timestamp":1660634218043,"user_tz":-180,"elapsed":260,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"d5aac5c3-6e56-4419-ecd5-afdb9418e6b0"},"source":["clf.estimators"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('lr', LogisticRegression(random_state=1)),\n"," ('rf', RandomForestClassifier(n_estimators=50, random_state=1)),\n"," ('gnb', GaussianNB())]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Средневзвешенные вероятности (мягкое голосование)\n","В отличие от голосования большинством (жесткое голосование) мягкое голосование возвращает метку класса как argmax суммы предсказанных вероятностей.\n","\n","\n","Каждому классификатору можно присвоить определенные веса с помощью weights параметра. Когда веса предоставлены, прогнозируемые вероятности классов для каждого классификатора собираются, умножаются на вес классификатора и усредняются. Окончательная метка класса затем получается из метки класса с наивысшей средней вероятностью.\n","\n","\n","Чтобы проиллюстрировать это на простом примере, предположим, что у нас есть 3 классификатора и 3 задачи классификации, в которых мы присваиваем всем классификаторам одинаковые веса: w1 = 1, w2 = 1, w3 = 1.\n","\n","Затем средневзвешенные вероятности для выборки будут рассчитаны следующим образом:\n","\n","классификатор\t1 класс\t2 класс\t3 класс\n","\n","классификатор 1\tw1 * 0,2\tw1 * 0,5\tw1 * 0,3\n","\n","классификатор 2\tw2 * 0,6\tw2 * 0,3\tw2 * 0,1\n","\n","классификатор 3\tw3 * 0,3\tw3 * 0,4\tw3 * 0,3\n","\n","средневзвешенное\t0,37\t0,4\t0,23\n","\n","Здесь метка предсказанного класса равна 2, так как она имеет самую высокую среднюю вероятность.\n","\n","В следующем примере показано, как области решений могут измениться при использовании программного обеспечения `VotingClassifier` на основе линейной машины опорных векторов, дерева решений и классификатора K-ближайших соседей:\n"],"metadata":{"id":"tQ0W5Ms5g5Bp"}},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from itertools import product\n","from sklearn.ensemble import VotingClassifier\n","\n","# Loading some example data\n","iris = datasets.load_iris()\n","X = iris.data[:, [0, 2]]\n","y = iris.target\n","\n","# Training classifiers\n","clf1 = DecisionTreeClassifier(max_depth=4)\n","clf2 = KNeighborsClassifier(n_neighbors=7)\n","clf3 = SVC(kernel='rbf', probability=True)\n","eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n","                         voting='soft', weights=[2, 1, 2])\n","\n","clf1 = clf1.fit(X, y)\n","clf2 = clf2.fit(X, y)\n","clf3 = clf3.fit(X, y)\n","eclf = eclf.fit(X, y)\n","\n","for clf, label in zip([clf1, clf2, clf3, eclf], ['DecisionTree', 'KNeighborst', 'SVC', 'VotingClassifier']):\n","     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n","     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CyEERdDOhEhl","executionInfo":{"status":"ok","timestamp":1660634381270,"user_tz":-180,"elapsed":5,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"3d0932af-0b5d-47e8-80d4-c02287206cdd"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.95 (+/- 0.03) [DecisionTree]\n","Accuracy: 0.94 (+/- 0.04) [KNeighborst]\n","Accuracy: 0.95 (+/- 0.03) [SVC]\n","Accuracy: 0.95 (+/- 0.03) [VotingClassifier]\n"]}]},{"cell_type":"markdown","metadata":{"id":"kjcNUJ9lHacv"},"source":["## Домашнее задание\n","\n","1. Повторите эксперимент, лабораторной работы.\n","2. Используя один из наборов данных, например, diabets проведите классификацию.\n","3. Оценить качество построенной модели, основываясь на матрице неточности и ROC-анализе.\n","4. Посмотрите на коэффициенты логистической регрессии финальной модели и скажите, результаты какого классификатора из ансамбля более важны?\n","5. Пробуйте самостоятельно другие данные, другие модели, другие параметры моделей."]}]}